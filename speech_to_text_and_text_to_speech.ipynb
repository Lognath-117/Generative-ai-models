import gradio as gr
import os
import numpy as np
import soundfile as sf
import wave
import json
from vosk import Model, KaldiRecognizer
from TTS.api import TTS

# Load Vosk model
vosk_model = Model(model_name="vosk-model-small-en-us-0.15")

# Load Coqui TTS model
coqui_tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False, gpu=False)

def transcribe_and_speak(audio):
    if audio is None:
        return "No audio provided", None

    # Save the audio to a file
    wav_path = "input.wav"
    sf.write(wav_path, audio, 16000)

    # Transcribe using Vosk
    wf = wave.open(wav_path, "rb")
    rec = KaldiRecognizer(vosk_model, wf.getframerate())
    rec.SetWords(True)

    text = ""
    while True:
        data = wf.readframes(4000)
        if len(data) == 0:
            break
        if rec.AcceptWaveform(data):
            result = json.loads(rec.Result())
            text += result.get("text", "") + " "
    result = json.loads(rec.FinalResult())
    text += result.get("text", "")

    # Generate speech using Coqui
    tts_output_path = "output.wav"
    coqui_tts.tts_to_file(text=text if text else "I didn't hear anything.", file_path=tts_output_path)

    return text, tts_output_path

# Gradio UI
gr.Interface(
    fn=transcribe_and_speak,
    inputs=gr.Audio(type="numpy", label="üéôÔ∏è Speak Something"),  # no 'source' parameter here
    outputs=[
        gr.Textbox(label="üìù Transcribed Text"),
        gr.Audio(label="üîä Coqui TTS Output")
    ],
    title="üß† Speech to Text & Back using Vosk + Coqui",
    description="üé§ Speak something and hear it back via AI!"
).launch()
