!pip install gradio coqui-ai-tts vosk soundfile numpy

import gradio as gr
import soundfile as sf
import numpy as np
import os
from vosk import Model, KaldiRecognizer
import json
import tempfile
from TTS.api import TTS

# Load models
vosk_model = Model(lang="en-us")  # Offline ASR model
tts = TTS(model_name="tts_models/en/ljspeech/tacotron2-DDC", progress_bar=False, gpu=False)  # Offline TTS model

# Speech to text
def speech_to_text(audio):
    if audio is None:
        return "No audio input provided."
    audio, samplerate = sf.read(audio)
    recognizer = KaldiRecognizer(vosk_model, samplerate)
    recognizer.AcceptWaveform(audio.tobytes())
    result = recognizer.Result()
    return json.loads(result).get("text", "")

# Text to speech
def text_to_speech(text):
    if not text:
        return None
    output_path = tempfile.mktemp(suffix=".wav")
    tts.tts_to_file(text=text, file_path=output_path)
    return output_path

# Master function
def run_app(input_mode, output_mode, text_input, audio_input):
    # Get input text
    input_text = ""
    if input_mode == "Text":
        input_text = text_input
    elif input_mode == "Speech":
        input_text = speech_to_text(audio_input)

    # Get output
    if output_mode == "Text":
        return input_text, None
    elif output_mode == "Speech":
        output_audio = text_to_speech(input_text)
        return "", output_audio

# Gradio UI
with gr.Blocks(title="üß† Speech ‚Üî Text Assistant") as app:
    gr.Markdown("## üéôÔ∏èüìù Offline Speech-Text Assistant using Vosk & Coqui")

    input_mode = gr.Radio(["Text", "Speech"], label="Input Mode", value="Text")
    output_mode = gr.Radio(["Text", "Speech"], label="Output Mode", value="Text")

    text_input = gr.Textbox(label="Input Text", visible=True)
    audio_input = gr.Audio(type="filepath", label="Input Speech", visible=False)

    run_button = gr.Button("üöÄ Run")

    text_output = gr.Textbox(label="Output Text")
    audio_output = gr.Audio(label="Output Speech")

    def toggle_visibility(input_mode):
        return {
            text_input: gr.update(visible=input_mode == "Text"),
            audio_input: gr.update(visible=input_mode == "Speech")
        }

    input_mode.change(toggle_visibility, inputs=[input_mode], outputs=[text_input, audio_input])

    run_button.click(
        run_app,
        inputs=[input_mode, output_mode, text_input, audio_input],
        outputs=[text_output, audio_output]
    )

app.launch()
